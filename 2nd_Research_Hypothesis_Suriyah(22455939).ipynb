{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "mount_file_id": "1GtR92_Se2ZoEgHdjcRC_8cEiOCp0PGD-",
      "authorship_tag": "ABX9TyNdYlDAoQX4GH1FZ0dq6JRk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/suriyah1310/6G7V0026_2223_9F/blob/main/2nd_Research_Hypothesis_Suriyah(22455939).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J81oKbvWX2tj"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Section 1: Installing relevant software & dictionaries:"
      ],
      "metadata": {
        "id": "FqLfAFvKgZVe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jLPQIeJkeyhJ",
        "outputId": "b64b6820-8e40-42fa-8f67-cee88b82accc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Setting up Spark and all relevant dictionaries: \n",
        "print(\"\\nWelcome to 2nd Research Hypothesis work by Suriyah Uthayakumar (22455939)\")\n",
        "!ls\n",
        "\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "!wget https://downloads.apache.org/spark/spark-3.3.2/spark-3.3.2-bin-hadoop3.tgz\n",
        "!tar -xf spark-3.3.2-bin-hadoop3.tgz\n",
        "!ls -alt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jwWyfUcley8X",
        "outputId": "156033dc-e41a-43cc-a41f-551c965d033f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Welcome to 2nd Research Hypothesis work by Suriyah Uthayakumar (22455939)\n",
            "sample_data  spark-3.3.2-bin-hadoop3  spark-3.3.2-bin-hadoop3.tgz\n",
            "--2023-04-24 18:25:03--  https://downloads.apache.org/spark/spark-3.3.2/spark-3.3.2-bin-hadoop3.tgz\n",
            "Resolving downloads.apache.org (downloads.apache.org)... 135.181.214.104, 88.99.95.219, 2a01:4f8:10a:201a::2, ...\n",
            "Connecting to downloads.apache.org (downloads.apache.org)|135.181.214.104|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 299360284 (285M) [application/x-gzip]\n",
            "Saving to: ‘spark-3.3.2-bin-hadoop3.tgz.1’\n",
            "\n",
            "spark-3.3.2-bin-had 100%[===================>] 285.49M  28.7MB/s    in 11s     \n",
            "\n",
            "2023-04-24 18:25:14 (26.8 MB/s) - ‘spark-3.3.2-bin-hadoop3.tgz.1’ saved [299360284/299360284]\n",
            "\n",
            "total 584716\n",
            "drwxr-xr-x  1 root root      4096 Apr 24 18:25 .\n",
            "drwxr-xr-x  1 root root      4096 Apr 24 18:23 ..\n",
            "drwxr-xr-x  1 root root      4096 Apr 21 13:38 sample_data\n",
            "drwxr-xr-x  4 root root      4096 Apr 21 13:37 .config\n",
            "-rw-r--r--  1 root root 299360284 Feb 10 21:28 spark-3.3.2-bin-hadoop3.tgz\n",
            "-rw-r--r--  1 root root 299360284 Feb 10 21:28 spark-3.3.2-bin-hadoop3.tgz.1\n",
            "drwxr-xr-x 13  501 1000      4096 Feb 10 20:40 spark-3.3.2-bin-hadoop3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!rm spark-3.3.2-bin-hadoop3.tgz.1"
      ],
      "metadata": {
        "id": "bgnczUF3ezVX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OPhTLbeOe0EQ",
        "outputId": "0f8cd6a4-77b0-4599-978d-785516b35f89"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sample_data  spark-3.3.2-bin-hadoop3  spark-3.3.2-bin-hadoop3.tgz\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#installing findspark \n",
        "!pip3 install findspark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MxtG8igNEOzi",
        "outputId": "79ecdf50-4436-480d-f6bd-ed50acb8d6a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting findspark\n",
            "  Downloading findspark-2.0.1-py2.py3-none-any.whl (4.4 kB)\n",
            "Installing collected packages: findspark\n",
            "Successfully installed findspark-2.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.3.2-bin-hadoop3\"\n",
        "import findspark\n",
        "findspark.init()\n",
        "from pyspark import SparkConf, SparkContext\n",
        "# Spark is started. 2 cores used:\n",
        "spark_conf = SparkConf().setMaster('local[2]').setAppName('MyApp')\n",
        "sc = SparkContext(conf=spark_conf)\n",
        "# Importing pyspark SQL for queries: \n",
        "from pyspark.sql import *\n",
        "from pyspark.sql.functions import *\n",
        "\n",
        "# Spark Session is started: \n",
        "# \"SparkSession\" and \"sc\" are key handles in to Spark API\n",
        "##SparkSession.builder.getOrCreate()\n",
        "spark = SparkSession.builder.appName(\"bikes2\").getOrCreate()"
      ],
      "metadata": {
        "id": "sIt_LRoBEZI5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XRsvsNVae0ev",
        "outputId": "4a724ef8-67ee-4e4e-ed52-8f102b7b0fc1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Section 2: Upload of datasets (TFL & Glasgow): "
      ],
      "metadata": {
        "id": "WqxepX_FD-9j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TFL open data for the year 2017-2021 London bike hire file is downloaded:\n",
        "\n",
        "#2017\n",
        "!wget https://cycling.data.tfl.gov.uk/usage-stats/63JourneyDataExtract21Jun2017-27Jun2017.csv"
      ],
      "metadata": {
        "id": "nBW9b3_ge01P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://cycling.data.tfl.gov.uk/usage-stats/64JourneyDataExtract28Jun2017-04Jul2017.csv https://cycling.data.tfl.gov.uk/usage-stats/65JourneyDataExtract05Jul2017-11Jul2017.csv https://cycling.data.tfl.gov.uk/usage-stats/66JourneyDataExtract12Jul2017-18Jul2017.csv https://cycling.data.tfl.gov.uk/usage-stats/67JourneyDataExtract19Jul2017-25Jul2017.csv https://cycling.data.tfl.gov.uk/usage-stats/68JourneyDataExtract26Jul2017-31Jul2017.csv https://cycling.data.tfl.gov.uk/usage-stats/69JourneyDataExtract01Aug2017-07Aug2017.csv https://cycling.data.tfl.gov.uk/usage-stats/70JourneyDataExtract08Aug2017-14Aug2017.csv https://cycling.data.tfl.gov.uk/usage-stats/71JourneyDataExtract15Aug2017-22Aug2017.csv https://cycling.data.tfl.gov.uk/usage-stats/72JourneyDataExtract23Aug2017-29Aug2017.csv https://cycling.data.tfl.gov.uk/usage-stats/73JourneyDataExtract30Aug2017-05Sep2017.csv https://cycling.data.tfl.gov.uk/usage-stats/74JourneyDataExtract06Sep2017-12Sep2017.csv https://cycling.data.tfl.gov.uk/usage-stats/75JourneyDataExtract13Sep2017-19Sep2017.csv https://cycling.data.tfl.gov.uk/usage-stats/76JourneyDataExtract20Sep2017-26Sep2017.csv "
      ],
      "metadata": {
        "id": "lbuMju5ze1ln"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#2018 data: \n",
        "!wget https://cycling.data.tfl.gov.uk/usage-stats/115JourneyDataExtract20June2018-26June2018.csv https://cycling.data.tfl.gov.uk/usage-stats/116JourneyDataExtract27June2018-03July2018.csv https://cycling.data.tfl.gov.uk/usage-stats/117JourneyDataExtract04July2018-10July2018.csv https://cycling.data.tfl.gov.uk/usage-stats/118JourneyDataExtract11July2018-17July2018.csv https://cycling.data.tfl.gov.uk/usage-stats/119JourneyDataExtract18July2018-24July2018.csv https://cycling.data.tfl.gov.uk/usage-stats/120JourneyDataExtract25July2018-31July2018.csv https://cycling.data.tfl.gov.uk/usage-stats/121JourneyDataExtract01Aug2018-07Aug2018.csv https://cycling.data.tfl.gov.uk/usage-stats/122JourneyDataExtract08Aug2018-14Aug2018.csv https://cycling.data.tfl.gov.uk/usage-stats/123JourneyDataExtract15Aug2018-21Aug2018.csv https://cycling.data.tfl.gov.uk/usage-stats/124JourneyDataExtract22Aug2018-28Aug2018.csv https://cycling.data.tfl.gov.uk/usage-stats/125JourneyDataExtract29Aug2018-04Sep2018.csv https://cycling.data.tfl.gov.uk/usage-stats/126JourneyDataExtract05Sep2018-11Sep2018.csv https://cycling.data.tfl.gov.uk/usage-stats/127JourneyDataExtract12Sep2018-18Sep2018.csv https://cycling.data.tfl.gov.uk/usage-stats/128JourneyDataExtract19Sep2018-25Sep2018.csv "
      ],
      "metadata": {
        "id": "upn_Taoqe17X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#2019 data:\n",
        "!wget https://cycling.data.tfl.gov.uk/usage-stats/167JourneyDataExtract19Jun2019-25Jun2019.csv https://cycling.data.tfl.gov.uk/usage-stats/168JourneyDataExtract26Jun2019-02Jul2019.csv https://cycling.data.tfl.gov.uk/usage-stats/169JourneyDataExtract03Jul2019-09Jul2019.csv https://cycling.data.tfl.gov.uk/usage-stats/170JourneyDataExtract10Jul2019-16Jul2019.csv https://cycling.data.tfl.gov.uk/usage-stats/171JourneyDataExtract17Jul2019-23Jul2019.csv https://cycling.data.tfl.gov.uk/usage-stats/172JourneyDataExtract24Jul2019-30Jul2019.csv https://cycling.data.tfl.gov.uk/usage-stats/173JourneyDataExtract31Jul2019-06Aug2019.csv https://cycling.data.tfl.gov.uk/usage-stats/174JourneyDataExtract07Aug2019-13Aug2019.csv https://cycling.data.tfl.gov.uk/usage-stats/175JourneyDataExtract14Aug2019-20Aug2019.csv https://cycling.data.tfl.gov.uk/usage-stats/176JourneyDataExtract21Aug2019-27Aug2019.csv https://cycling.data.tfl.gov.uk/usage-stats/177JourneyDataExtract28Aug2019-03Sep2019.csv https://cycling.data.tfl.gov.uk/usage-stats/178JourneyDataExtract04Sep2019-10Sep2019.csv https://cycling.data.tfl.gov.uk/usage-stats/179JourneyDataExtract11Sep2019-17Sep2019.csv https://cycling.data.tfl.gov.uk/usage-stats/180JourneyDataExtract18Sep2019-24Sep2019.csv "
      ],
      "metadata": {
        "id": "ClIcy4OFe2UY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#2020 data: \n",
        "!wget https://cycling.data.tfl.gov.uk/usage-stats/219JourneyDataExtract17Jun2020-23Jun2020.csv https://cycling.data.tfl.gov.uk/usage-stats/220JourneyDataExtract24Jun2020-30Jun2020.csv https://cycling.data.tfl.gov.uk/usage-stats/221JourneyDataExtract01Jul2020-07Jul2020.csv https://cycling.data.tfl.gov.uk/usage-stats/222JourneyDataExtract08Jul2020-14Jul2020.csv https://cycling.data.tfl.gov.uk/usage-stats/223JourneyDataExtract15Jul2020-21Jul2020.csv https://cycling.data.tfl.gov.uk/usage-stats/224JourneyDataExtract22Jul2020-28Jul2020.csv https://cycling.data.tfl.gov.uk/usage-stats/225JourneyDataExtract29Jul2020-04Aug2020.csv https://cycling.data.tfl.gov.uk/usage-stats/226JourneyDataExtract05Aug2020-11Aug2020.csv https://cycling.data.tfl.gov.uk/usage-stats/227JourneyDataExtract12Aug2020-18Aug2020.csv https://cycling.data.tfl.gov.uk/usage-stats/228JourneyDataExtract19Aug2020-25Aug2020.csv https://cycling.data.tfl.gov.uk/usage-stats/229JourneyDataExtract26Aug2020-01Sep2020.csv https://cycling.data.tfl.gov.uk/usage-stats/230JourneyDataExtract02Sep2020-08Sep2020.csv https://cycling.data.tfl.gov.uk/usage-stats/231JourneyDataExtract09Sep2020-15Sep2020.csv https://cycling.data.tfl.gov.uk/usage-stats/232JourneyDataExtract16Sep2020-22Sep2020.csv"
      ],
      "metadata": {
        "id": "rK319E1te2sH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#2021 data: \n",
        "!wget https://cycling.data.tfl.gov.uk/usage-stats/270JourneyDataExtract16Jun2021-22Jun2021.csv https://cycling.data.tfl.gov.uk/usage-stats/271JourneyDataExtract23Jun2021-29Jun2021.csv https://cycling.data.tfl.gov.uk/usage-stats/272JourneyDataExtract30Jun2021-06Jul2021.csv https://cycling.data.tfl.gov.uk/usage-stats/273JourneyDataExtract07Jul2021-13Jul2021.csv https://cycling.data.tfl.gov.uk/usage-stats/274JourneyDataExtract14Jul2021-20Jul2021.csv https://cycling.data.tfl.gov.uk/usage-stats/275JourneyDataExtract21Jul2021-27Jul2021.csv https://cycling.data.tfl.gov.uk/usage-stats/276JourneyDataExtract28Jul2021-03Aug2021.csv https://cycling.data.tfl.gov.uk/usage-stats/277JourneyDataExtract04Aug2021-10Aug2021.csv https://cycling.data.tfl.gov.uk/usage-stats/278JourneyDataExtract11Aug2021-17Aug2021.csv https://cycling.data.tfl.gov.uk/usage-stats/279JourneyDataExtract18Aug2021-24Aug2021.csv https://cycling.data.tfl.gov.uk/usage-stats/280JourneyDataExtract25Aug2021-31Aug2021.csv https://cycling.data.tfl.gov.uk/usage-stats/281JourneyDataExtract01Sep2021-07Sep2021.csv https://cycling.data.tfl.gov.uk/usage-stats/282JourneyDataExtract08Sep2021-14Sep2021.csv https://cycling.data.tfl.gov.uk/usage-stats/283JourneyDataExtract15Sep2021-21Sep2021.csv https://cycling.data.tfl.gov.uk/usage-stats/284JourneyDataExtract22Sep2021-28Sep2021.csv"
      ],
      "metadata": {
        "id": "tVRdK3Y1e3Gv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Uploading 2nd dataset (Glasglow Next Bike Cycle Hire's data) of the year 2017-2022. \n",
        "#Since this file did not have an online link, the file is uploaded into colab.  \n",
        "\n",
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "id": "CLQqSR6ze3dH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "outputId": "0e214455-3f87-449c-de13-79a59712a608"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-fadbee70-3cb5-4b21-9c8e-274298c62338\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-fadbee70-3cb5-4b21-9c8e-274298c62338\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving Next_Bike_Cycle_Hire_Glasgow_Trip_Data_(2017-2022).csv to Next_Bike_Cycle_Hire_Glasgow_Trip_Data_(2017-2022).csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "z9xLO6sXe34n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# The Second Research Hypothesis:\n",
        " ## “Between 5 years (2017-2021) period, the trend of cycle usage during Summer is more in London compared to Glasgow”"
      ],
      "metadata": {
        "id": "54xto-WJFaCe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Section 3: Filtering required Data:"
      ],
      "metadata": {
        "id": "dckZc9rNOXC5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Defining Summer: a) London"
      ],
      "metadata": {
        "id": "ZpynKzrqPGfP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# According to (metoffice.gov.uk), Summer is defined between the period 21st June - 23 Sep. \n",
        "\n",
        "# The London (TFL) data for the above mentioned 5 years is present in the following different files namely, \n",
        "# 2017 - 63* - 76* (14 files)\n",
        "# 2018 - 115* - 128* (14 files)\n",
        "# 2019 - 167* - 180* (14 files)\n",
        "# 2020 - 219* - 232* (13 files)\n",
        "# 2021 - 270* - 284* (14 files)"
      ],
      "metadata": {
        "id": "CYBhIusee5kQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Reading these files into a new dataframe called london1721_df\n",
        "\n",
        "\n",
        "london1721_df = (spark.read.format(\"csv\")\n",
        "         .option(\"header\", \"true\")\n",
        "         .option(\"inferSchema\", \"true\")\n",
        "         .load(['./1*csv', './2*csv', './6*csv', './7*csv' ]))\n"
      ],
      "metadata": {
        "id": "sBdPRO1Me55H"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"The London dataset (5 years) dataframe has\", london1721_df.count(), \" entries\") "
      ],
      "metadata": {
        "id": "CCDEixfWe6OT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c5c8edf2-00e0-482b-924e-a34de75cb02d"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The London dataset (5 years) dataframe has 17900251  entries\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Printing the schema to check the column details: \n",
        "\n",
        "london1721_df.printSchema()"
      ],
      "metadata": {
        "id": "xfbvl-GLe6l3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a7263bb1-a641-46ab-e514-5476258b059c"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- Rental Id: string (nullable = true)\n",
            " |-- Duration: string (nullable = true)\n",
            " |-- Bike Id: string (nullable = true)\n",
            " |-- End Date: string (nullable = true)\n",
            " |-- EndStation Id: string (nullable = true)\n",
            " |-- EndStation Name: string (nullable = true)\n",
            " |-- Start Date: string (nullable = true)\n",
            " |-- StartStation Id: string (nullable = true)\n",
            " |-- StartStation Name: string (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "london1721_df.show(2)"
      ],
      "metadata": {
        "id": "PA8gOzDge69n",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cebce9f1-3f21-4941-fbbd-7c3e4af4fa5a"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+--------+-------+----------------+-------------+--------------------+----------------+---------------+--------------------+\n",
            "|Rental Id|Duration|Bike Id|        End Date|EndStation Id|     EndStation Name|      Start Date|StartStation Id|   StartStation Name|\n",
            "+---------+--------+-------+----------------+-------------+--------------------+----------------+---------------+--------------------+\n",
            "|102217368|     600|   6998|22/09/2020 14:01|          318|Sackville Street,...|22/09/2020 13:51|            303|Albert Gate, Hyde...|\n",
            "|102217345|     660|    882|22/09/2020 14:01|           66|Holborn Circus, H...|22/09/2020 13:50|            263|St. Mary Axe, Ald...|\n",
            "+---------+--------+-------+----------------+-------------+--------------------+----------------+---------------+--------------------+\n",
            "only showing top 2 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# This london1721 data has some unwanted dates i.e, we need only the dates between 21 June - 23 Sep which is \"Summer\" for all the 5 years: \n",
        "\n",
        "#Cleansing year-wise & formaing a union of all years put together in a dataframe named \"summer_london\"\n",
        "\n",
        "# conversion to expected timestamp format so can filter, and alias so easily refer to 'Start'\n",
        "#2017:\n",
        "temp_2017_df = london1721_df.select(to_timestamp(col(\"Start Date\"), format=\"dd/MM/yyyy HH:mm\").alias(\"Start\"), \"Duration\", \"Bike Id\")\n",
        "#2018:\n",
        "temp_2018_df = london1721_df.select(to_timestamp(col(\"Start Date\"), format=\"dd/MM/yyyy HH:mm\").alias(\"Start\"), \"Duration\", \"Bike Id\")\n",
        "#2019:\n",
        "temp_2019_df = london1721_df.select(to_timestamp(col(\"Start Date\"), format=\"dd/MM/yyyy HH:mm\").alias(\"Start\"), \"Duration\", \"Bike Id\")\n",
        "#2020:\n",
        "temp_2020_df = london1721_df.select(to_timestamp(col(\"Start Date\"), format=\"dd/MM/yyyy HH:mm\").alias(\"Start\"), \"Duration\", \"Bike Id\")\n",
        "#2021:\n",
        "temp_2021_df = london1721_df.select(to_timestamp(col(\"Start Date\"), format=\"dd/MM/yyyy HH:mm\").alias(\"Start\"), \"Duration\", \"Bike Id\")\n",
        "\n",
        "# Firstly, filtering 2017 data to the required dates (21 JUNE 2017 - 23 SEP 2017)\n",
        "\n",
        "summer_2017_london_df = temp_2017_df.filter(temp_2017_df.Start > \"2017-06-20 23:59:59\")\\\n",
        ".filter(temp_2017_df.Start < \"2017-09-24 00:00:00\")[[\"Start\", \"Duration\", \"Bike Id\"]]\n",
        "\n",
        "# Checking whether filtered correctly;\n",
        "summer_2017_london_df.sort(\"Start\", ascending = True).show(5)\n",
        "summer_2017_london_df.sort(\"Start\", ascending = False).show(5)"
      ],
      "metadata": {
        "id": "yR37UZVce8KP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4b667d1e-770a-42d9-8a7f-be59ceb1f45c"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------------+--------+-------+\n",
            "|              Start|Duration|Bike Id|\n",
            "+-------------------+--------+-------+\n",
            "|2017-06-21 00:00:00|    1800|   3304|\n",
            "|2017-06-21 00:00:00|    1320|  12498|\n",
            "|2017-06-21 00:00:00|    1800|  12845|\n",
            "|2017-06-21 00:00:00|     420|   5801|\n",
            "|2017-06-21 00:00:00|     360|   6242|\n",
            "+-------------------+--------+-------+\n",
            "only showing top 5 rows\n",
            "\n",
            "+-------------------+--------+-------+\n",
            "|              Start|Duration|Bike Id|\n",
            "+-------------------+--------+-------+\n",
            "|2017-09-23 23:59:00|    2760|   1185|\n",
            "|2017-09-23 23:59:00|     540|   8191|\n",
            "|2017-09-23 23:59:00|    1440|  14130|\n",
            "|2017-09-23 23:59:00|     840|   2575|\n",
            "|2017-09-23 23:59:00|    2700|   7797|\n",
            "+-------------------+--------+-------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Now the summer_2017_london has the exact dates of Summer 2017. \n",
        "# Let's get the same for the rest of the years. \n",
        "\n",
        "summer_2018_london_df = temp_2018_df.filter(temp_2018_df.Start > \"2018-06-20 23:59:59\")\\\n",
        ".filter(temp_2018_df.Start < \"2018-09-24 00:00:00\")[[\"Start\", \"Duration\", \"Bike Id\"]]\n",
        "\n",
        "summer_2019_london_df = temp_2019_df.filter(temp_2019_df.Start > \"2019-06-20 23:59:59\")\\\n",
        ".filter(temp_2019_df.Start < \"2019-09-24 00:00:00\")[[\"Start\", \"Duration\", \"Bike Id\"]]\n",
        "\n",
        "summer_2020_london_df = temp_2020_df.filter(temp_2020_df.Start > \"2020-06-20 23:59:59\")\\\n",
        ".filter(temp_2020_df.Start < \"2020-09-24 00:00:00\")[[\"Start\", \"Duration\", \"Bike Id\"]]\n",
        "\n",
        "summer_2021_london_df = temp_2021_df.filter(temp_2021_df.Start > \"2021-06-20 23:59:59\")\\\n",
        ".filter(temp_2021_df.Start < \"2021-09-24 00:00:00\")[[\"Start\", \"Duration\", \"Bike Id\"]]"
      ],
      "metadata": {
        "id": "yCAPMFWxe9Kn"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Union of all years put together in a dataframe named \"summer_london\"\n",
        "\n",
        "summer_london_df = summer_2017_london_df.union(summer_2018_london_df)\\\n",
        ".union(summer_2019_london_df).union(summer_2020_london_df)\\\n",
        ".union(summer_2021_london_df)"
      ],
      "metadata": {
        "id": "x3R8jse6e9ef"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "summer_london_df.count()"
      ],
      "metadata": {
        "id": "Udr7Qfd-e9xv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "75606bb5-b2fb-49e0-8803-4d28ca1c213c"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "17089781"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KyL4efbue-Ff"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Defining Summer: b) Glasgow"
      ],
      "metadata": {
        "id": "s6Evxht4kqVZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# The Next Bike cycle hire's Glasgow dataset has entire rides data that has happened between 2017-2022.\n",
        "# But the specific dates of interest are: (21 June - 23 Sep) for the years 2017 - 2021. \n",
        "\n",
        "# Firslty, reading this entire dataset into a new dataframe called glasgow1722_df\n",
        "\n",
        "\n",
        "glasgow1722_df = (spark.read.format(\"csv\")\n",
        "         .option(\"header\", \"true\")\n",
        "         .option(\"inferSchema\", \"true\")\n",
        "         .load(['./Next*csv' ]))"
      ],
      "metadata": {
        "id": "z_gib7ZXe-Xf"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"The Entire Glasgow dataset (6 years) dataframe has\", glasgow1722_df.count(), \" entries\")"
      ],
      "metadata": {
        "id": "AmtuCJzGe-u_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2e00ab6c-abc1-45a9-cdc6-487796135201"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Entire Glasgow dataset (6 years) dataframe has 1419993  entries\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Printing the schema to check the column details: \n",
        "\n",
        "glasgow1722_df.printSchema()"
      ],
      "metadata": {
        "id": "_ciYRsUse_N3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7efb7095-d6d6-48f7-e592-d3730b5e3778"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- Start time: timestamp (nullable = true)\n",
            " |-- End time: timestamp (nullable = true)\n",
            " |-- Duration: integer (nullable = true)\n",
            " |-- Rental place: string (nullable = true)\n",
            " |-- Return place: string (nullable = true)\n",
            " |-- START LAT: string (nullable = true)\n",
            " |-- START LONG: string (nullable = true)\n",
            " |-- END LAT: double (nullable = true)\n",
            " |-- END LONG: double (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# This Glasgow data has some unwanted dates i.e, we need only the dates between 21 June - 23 Sep which is \n",
        "# \"Summer\" for all the 5 years only (2017-2021): \n",
        "\n",
        "# Cleansing year-wise & formaing a union of all years put together in a dataframe named \"summer_glasgow\"\n",
        "\n",
        "# conversion to expected timestamp format so can filter, and alias so easily refer to 'Start'\n",
        "#2017:\n",
        "g_2017_df = glasgow1722_df.select(to_timestamp(col(\"Start time\"), format=\"dd/MM/yyyy HH:mm\").alias(\"Start\"), \"Duration\")\n",
        "#2018:\n",
        "g_2018_df = glasgow1722_df.select(to_timestamp(col(\"Start time\"), format=\"dd/MM/yyyy HH:mm\").alias(\"Start\"), \"Duration\")\n",
        "#2019:\n",
        "g_2019_df = glasgow1722_df.select(to_timestamp(col(\"Start time\"), format=\"dd/MM/yyyy HH:mm\").alias(\"Start\"), \"Duration\")\n",
        "#2020:\n",
        "g_2020_df = glasgow1722_df.select(to_timestamp(col(\"Start time\"), format=\"dd/MM/yyyy HH:mm\").alias(\"Start\"), \"Duration\")\n",
        "#2021:\n",
        "g_2021_df = glasgow1722_df.select(to_timestamp(col(\"Start time\"), format=\"dd/MM/yyyy HH:mm\").alias(\"Start\"), \"Duration\")\n",
        "\n",
        "# Filtering all the years to the required dates (21 JUNE 2017 - 23 SEP 2017)\n",
        "\n",
        "summer_2017_gg_df = g_2017_df.filter(g_2017_df.Start > \"2017-06-20 23:59:59\")\\\n",
        ".filter(g_2017_df.Start < \"2017-09-24 00:00:00\")[[\"Start\", \"Duration\"]]\n",
        "\n",
        "summer_2018_gg_df = g_2018_df.filter(g_2018_df.Start > \"2018-06-20 23:59:59\")\\\n",
        ".filter(g_2018_df.Start < \"2018-09-24 00:00:00\")[[\"Start\", \"Duration\"]]\n",
        "\n",
        "summer_2019_gg_df = g_2019_df.filter(g_2019_df.Start > \"2019-06-20 23:59:59\")\\\n",
        ".filter(g_2019_df.Start < \"2019-09-24 00:00:00\")[[\"Start\", \"Duration\"]]\n",
        "\n",
        "summer_2020_gg_df = g_2020_df.filter(g_2020_df.Start > \"2020-06-20 23:59:59\")\\\n",
        ".filter(g_2020_df.Start < \"2020-09-24 00:00:00\")[[\"Start\", \"Duration\"]]\n",
        "\n",
        "summer_2021_gg_df = g_2021_df.filter(g_2021_df.Start > \"2021-06-20 23:59:59\")\\\n",
        ".filter(g_2021_df.Start < \"2021-09-24 00:00:00\")[[\"Start\", \"Duration\"]]"
      ],
      "metadata": {
        "id": "0QEXQvtse_hG"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Union of all years put together in a dataframe named \"summer_gg\" gives the Glasgow Summer data for 5 years\n",
        "\n",
        "summer_gg_df = summer_2017_gg_df.union(summer_2018_gg_df)\\\n",
        "              .union(summer_2019_gg_df).union(summer_2020_gg_df)\\\n",
        "              .union(summer_2021_gg_df)\n",
        "\n",
        "print(\"After data cleaning, the only Summer data of the years 2017-2021 Glasgow dataset has: \" , summer_gg_df.count() , \"entries\")\n",
        "\n"
      ],
      "metadata": {
        "id": "qO-FOOY2e_13",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3295ceb0-929d-4df2-8e50-eb2216365adf"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "After data cleaning, the only Summer data of the years 2017-2021 Glasgow dataset has:  332505 entries\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "H00ONeiofAla"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Section 4: Stratified Sampling: \n",
        "\n"
      ],
      "metadata": {
        "id": "lDWYbasYtkD8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Taking stratified statistical sampling method to attain data from all the 5 years: \n",
        "# i.e, 2017(1%), 2018(1%), 2019(1%), 2020(1%), 2021(1%)"
      ],
      "metadata": {
        "id": "TxPlh270fA8f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extracting Year from date format column: "
      ],
      "metadata": {
        "id": "alKZHdHbfBVH"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pyspark.sql.functions as f"
      ],
      "metadata": {
        "id": "GaWn6O13fBqP"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Using to_timestamp api of functions package to extract years from the data and stored in a new column 'years'\n",
        "\n",
        "london_year_df = summer_london_df.withColumn('years',f.year(f.to_timestamp('Start', 'dd/MM/yyyy')))"
      ],
      "metadata": {
        "id": "jcrWcDvPfCDX"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Checking if it worked all well: \n",
        "london_year_df.sort(\"Start\", ascending = False).show(5)"
      ],
      "metadata": {
        "id": "h71P-lIDfCcP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "518d3226-ac89-45eb-d9bb-5b3bca24f01a"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------------+--------+-------+-----+\n",
            "|              Start|Duration|Bike Id|years|\n",
            "+-------------------+--------+-------+-----+\n",
            "|2021-09-23 23:59:00|     840|  16767| 2021|\n",
            "|2021-09-23 23:59:00|     720|   8392| 2021|\n",
            "|2021-09-23 23:59:00|    1380|  13121| 2021|\n",
            "|2021-09-23 23:59:00|    1800|   6934| 2021|\n",
            "|2021-09-23 23:59:00|     240|  20232| 2021|\n",
            "+-------------------+--------+-------+-----+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Now, stratified statistical sampling by each year (1%) from the whole london data: \n",
        "\n",
        "london_sample_df = london_year_df.sampleBy(\"years\", fractions={2017: 0.01, 2018: 0.01, 2019: 0.01, 2020: 0.01, 2021: 0.01 }, seed=10)\n",
        "london_sample_df.count()"
      ],
      "metadata": {
        "id": "cqKzyb4mfC03",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9cb1a06d-f3e6-4f51-cd61-3b7b937b0b64"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "170516"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Using to_timestamp api of functions package to extract years from the data and stored in a new column 'years'\n",
        "\n",
        "gg_year_df = summer_gg_df.withColumn('years',f.year(f.to_timestamp('Start', 'dd/MM/yyyy')))\n",
        "\n",
        "#Checking if it worked all well: \n",
        "gg_year_df.sort(\"Start\", ascending = False).show(2)"
      ],
      "metadata": {
        "id": "Shi5tlACfDMH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "55fc05ab-16b9-44c7-e438-8863ed1ae433"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------------+--------+-----+\n",
            "|              Start|Duration|years|\n",
            "+-------------------+--------+-----+\n",
            "|2021-09-23 23:58:00|     819| 2021|\n",
            "|2021-09-23 23:58:00|     225| 2021|\n",
            "+-------------------+--------+-----+\n",
            "only showing top 2 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Now, stratified statistical sampling by each year (50%) from the whole glasgow data: \n",
        "# Since the overall glasgow data is only around 3M but the london whole data has about 17M, \n",
        "# inorder to get similar amount of sample 50% is taken here and 1% at london data. \n",
        "\n",
        "gg_sample_df = gg_year_df.sampleBy(\"years\", fractions={2017: 0.5, 2018: 0.5, 2019: 0.5, 2020: 0.5, 2021: 0.5 }, seed=10)\n",
        "gg_sample_df.count()"
      ],
      "metadata": {
        "id": "ZxUj62mvfDiv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4a949f44-117a-4a7d-9c09-c293204cdd7b"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "166529"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "london_sample_df.printSchema()\n",
        "gg_sample_df.printSchema()"
      ],
      "metadata": {
        "id": "GNIceu3xfEOH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0aa9bbe3-3bd1-475a-b8f3-867519d661dd"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- Start: timestamp (nullable = true)\n",
            " |-- Duration: string (nullable = true)\n",
            " |-- Bike Id: string (nullable = true)\n",
            " |-- years: integer (nullable = true)\n",
            "\n",
            "root\n",
            " |-- Start: timestamp (nullable = true)\n",
            " |-- Duration: integer (nullable = true)\n",
            " |-- years: integer (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Since the london data's Duration column is string, changing it to integer \n",
        "\n",
        "from pyspark.sql.types import *\n",
        "\n",
        "# Change column type\n",
        "ln_sample_df = london_sample_df.withColumn(\"Duration\", london_sample_df[\"Duration\"].cast(IntegerType()))\n",
        "ln_sample_df.printSchema()\n",
        "ln_sample_df.select(\"Duration\").show(2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8c61UyI38c5G",
        "outputId": "3464fadf-2aaa-49c5-d793-a990026ba418"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- Start: timestamp (nullable = true)\n",
            " |-- Duration: integer (nullable = true)\n",
            " |-- Bike Id: string (nullable = true)\n",
            " |-- years: integer (nullable = true)\n",
            "\n",
            "+--------+\n",
            "|Duration|\n",
            "+--------+\n",
            "|     780|\n",
            "|   11400|\n",
            "+--------+\n",
            "only showing top 2 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Section 5: Finding the trend: "
      ],
      "metadata": {
        "id": "ORANHeMN6r5E"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZuZPQ_kpfEkv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "09bXey4HfE4H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iOJcRBZ_fFMf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rxJtjidyfFhv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dJOZ56-BfF23"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4-0eK8FFfGOG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bn5ahWHffGiH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sZDS-lUkfG5m"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}